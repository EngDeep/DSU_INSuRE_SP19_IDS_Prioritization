{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsGBsKuGdfXA"
   },
   "source": [
    "## Prelim Report \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A58zVsVW5rK0"
   },
   "source": [
    "\n",
    "** Keywords: **  \n",
    "IDS, intrusion detection, alert correlation, alert reduction, alert prioritization, CSE-CIC-IDS2018, clustering, machine learning, KDD CUP 99, Data Mining, NIDS, ensemble learning, support vector machines, anomaly based detection, K-means, N-gram, neural network, random forest\n",
    "\n",
    "**Project Description:  **\n",
    "We will be researching data science and machine learning techniques that can be used to fine tune an Intrusion Detection System (IDS).  The goal of this research is to create a working prototype to aid in the reduction of customizations organizations need to make when implementing and maintaining a working and effective IDS.  This prototype could then be further enhanced by future research teams.\n",
    "\n",
    "**Research Problem: **\n",
    "Intrusion Detection Systems (IDS) are notorious for requiring extensive adjustment and tailoring for each specific network they are deployed on. Efforts are needed to reduce the large number of false positives that many signatures can generate. Analysts must spend a lot of time assessing alerts to determine whether or not they are true positives and, if so, whether or not they are also severe enough to warrant acting on those alerts. Signatures that generate too many false positives are often simply turned off to avoid the distractions and noise they generate. This leaves systems open to possible hidden attack vectors. \n",
    "Can we instead combine multiple weak, high-false-positive signatures to generate high value, low-false-positive strong indicators? Can we incorporate other knowledge to further reduce false positives, and point analysts to the events they truly need to focus on? Can we do this at scale, without requiring analysts to manually define the correlations? \n",
    "\n",
    "**Objectives: **\n",
    "The first objective of this project is to explore the nature of many weak indicators or low priority alerts, which when combined together may be redressed in order to create a few strong indicators of intrusion.  Once we have investigated which of these weak indicators may be complementary, the ultimate goal would be to create a working model for applying data analysis techniques to look for other unknown patterns in this low priority subset. The working model would then be used to test against a large dataset and eventually be implemented in an IDS platform as a prototype. To achieve this objective, we will first determine if there are currently any established models for pattern recognition that can be trusted and compared for effectiveness within these low priority alerts.  If no such models yield effective results, we would then work towards building our own prototype that can be tested and then implemented into a current IDS. \n",
    "\n",
    "**Literature Review:**\n",
    "Our review of current literature focused on determining steps that had already been taken by other researchers in this field, learning about the various machine learning techniques already in use, and finding information to assist us in selecting our dataset and methods.  This section highlights some of the information that was reviewed.\n",
    "\n",
    "Starting with research that has been taken by others in the field, we found that many of these methods focused on using the KDD CUP 99 datasets.  Using this dataset researchers have tested machine learning techniques using both alert-based and anomaly-based detection techniques.  (Vaarandi, 2009) (Divekar, 2018)  Additionally we reviewed literature to assist in narrowing our focus of machine learning methods that would best suit our purposes.  A survey paper by Buczak and Guven described existing literature regarding machine learning and data mining methods including a description of each method.  (Buczak, 2016)   Our initial literature review concluded with information to assist in selecting our dataset.  In finding that many of the previous research had focused on the KDD CUP 99 dataset, we sought a more current alternative that has not been as thoroughly used, however we would start off with a more well known and previously used method to initially get a working prototype from which to improve.   A report from 2018 by Divekar, et al. benchmarked the KDD CUP 99 dataset with more modern datasets using Neural Network, Support Vector Machine, Decision Tree, Random Forest, Naive Bayes and K-Means.  (Divekar, 2018)  We continue to review literature as needed to assist us in our research. Of these the most frequently used appeard to be K-Means clustering. So we would decide to start our efforts here, and then compliment this with branching out into the lesser used techniques.\n",
    "\n",
    "**Chosen Dataset - CSE-CIC-IDS2018:**\n",
    "Our team evaluated numerous IDS traffic datasets in order to determine the most suitable for our research needs. During our evaluation the KDD CUP 99 dataset stood out as the most frequently used for this type of application. KDD CUP 99 was created in 1999 and may not accurately represent the current state of cyber attacks. For this reason, our group decided to choose a more current dataset, CSE-CIC-IDS2018. This dataset was created in 2018 by the Canadian Institute of Cybersecurity. CSE-CIC-IDS2018 is a large dataset which has examples of various relevant attacker activity. We feel this dataset will give the best representation of the attacks IDS operators will be facing today.\n",
    "\n",
    "**Initial Testing of K-MEANS machine learning method:**\n",
    "\n",
    "It was decided early on to use simpler and more visually explorative methods of unsupervised learning without the benefit of using our dataset's labels, in order to gain an intuition of the obvious patterns within our data. As such this use of K-means is our first \"Hello World\" style attepmt at cleaning and visualizing the data in order to inform our next steps going forward. Additionally K-means is somewhat traditional in the IDS world when using Machine Learning in order to detect anamalous behavior such as a \"Zero Day\" style attack might produce. Therefore, it gives us the fastest means to an early prototype, in addition to the quantatative results, which provides our up and coming machine learning prototypes with a more practical basis for comparison.\n",
    "\n",
    "**Discussed initial results: **\n",
    "From the results, after conducting the k-means approach on a sample of our dataset it is easy to see where K-means falls apart as an effective method for our intentions. K-means makes some assumptions about the physical structure of the data that our dataset fails to conform to.\n",
    "\n",
    "Additionally, investigation of the data points that were labeled as “anomalous” resulted in no consistent pattern according to the known threats within the dataset. Therefore the conclusion of our group is that a different method must be used in order to find a more effective score system. The top priority going forward is to find a method which will give us a confidence value for each datapoint that it is potentially a threat.\n",
    "\n",
    "**Investigating Random Forest Algorithm:**\n",
    "As a next step after our first coding prototype example, we will be evaluating more complex machine learning approaches to help solve our research problem. We have currently identified random forest classification as a potentially useful algorithm of classifying our dataset. We believe that random forest classification is a good approach due to its flexibility and ease of use in classification tasks.\n",
    "\n",
    "**Investigating the use of Neural Networks using LSTM:**\n",
    "\n",
    "Implementing Machine Learning to identify unknowns from the given data set can become challenging both in how to implement the algorithm to the provided data and to identify which algorithm works best for the given data set.  Additionally at times it may be driven by the expected result from the final model. This requires comparison and analysis of multiple machine learning algorithms to determine the model that best fits both the provided data structure and expected result. Neural Networks is one of the most complex machine learning algorithms. Our hypothesis is that it will do more accurately identify unknown relationships between different columns in the data set.  This newly identified relationship can then help us make an unknown conclusion from the data. In our project, we need to input the IDS dataset and prioritize the alerts to narrow down and accurately identify true or false alerts. Since the dataset of this nature (network traffic) is heavy with multidimensional relationships between them, an LSTM Neural Network can be beneficial in identifying unknown relations to achieve expected result in identifying true and false alerts more accurately. \n",
    "\n",
    "**Evaluate best approach and outcome:**\n",
    "Once we have explored the additional approaches to solving our research problem we will need to quantitatively identify the best approach. We will leverage confusion matrices to compare and contrast the results from each approach explored. The approach with the best results will be the chosen approach for our study.\n",
    "\n",
    "**Check effectiveness of a chosen approach on subsequent datasets:**\n",
    "We will be able to further evaluate our chosen approach by leveraging a prior, unlabeled version of our dataset, CIC-IDS2017. This older dataset uses the same format as the current 2018 version which allows us to seamlessly evaluate the results.\n",
    "\n",
    "**Create prioritization score: **\n",
    "We intend to change our initial assumption that an unsupervised method would be best, because we also have the benefit of a previously labeled dataset. We intend to use a sample of our labeled data for training of a supervised method and then use this method to devise a confidence value that a data vector is indeed a threat. \n",
    "\n",
    "This is in opposition to our original assumption that our best method should be an unsupervised one. This decision is due to our preliminary analysis results as demonstrated by K-means as in our first coding example. Many methods used by security researchers in previous studies have been concerned with so called \"zero day attacks\" and while unsupervised methods are highly advantageous for such attacks, they are less of a concern with reguard to our own goal; which is, to meerly prioritize or rank already suspected attacks as a subset of the whole group. Therefore our decision to study Random Forest Decision Trees and LSTM network learning will be more appropriate to our overall goal as they can benefit from our labeled dataset.\n",
    "\n",
    "--------------------------------\n",
    "***References ***\n",
    "\n",
    "*Buczak, A. L., & Guven, E. (2016). A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection. IEEE Communications Surveys and Tutorials, 18(2), 1153–1176. https://doi.org/10.1109/COMST.2015.2494502*\n",
    "\n",
    "*Dias, L. P, J. J. F Cerqueira, K. D. R Assis, and R. C Almeida. \"Using Artificial Neural Network in Intrusion Detection Systems to Computer Networks.\" 2017 9th Computer Science and Electronic Engineering (CEEC) (2017): 145-50. Web.*\n",
    "\n",
    "*Divekar, A., Parekh, M., Savla, V., Mishra, R., & Shirole, M. (2018). Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD CUP 99 alternatives.https://doi.org/arXiv:1811.05372v1*\n",
    "\n",
    "*Dobson, A. (2018). Performance Evaluation of Machine Learning Algorithms in Apache Spark for Intrusion Detection. Retrieved from http://search.proquest.com/openview/cbc9aa27adb04230859dc1d7ca27686c/1?pq-origsite=gscholar&cbl=18750&diss=y*\n",
    "\n",
    "*Kenaza, T., Labed, A., Boulahia, Y., & Sebehi, M. (2015). Adaptive SVDD-based Learning for False Alarm Reduction in Intrusion Detection (pp. 405–412). Scitepress. https://doi.org/10.5220/0005573204050412*\n",
    "\n",
    "*Mirza, A. H. (2018). Computer network intrusion detection using various classifiers and ensemble learning. In 26th IEEE Signal Processing and Communications Applications Conference, SIU 2018 (pp. 1–4). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/SIU.2018.8404704*\n",
    "\n",
    "*Njogu, H. W., & Luo, L. (2010). Using Alert Cluster to reduce IDS alerts. In Proceedings - 2010 3rd IEEE International Conference on Computer Science and Information Technology, ICCSIT 2010 (Vol. 5, pp. 467–471). https://doi.org/10.1109/ICCSIT.2010.5563925*\n",
    "\n",
    "*Renners, L., Heine, F., & Rodosek, G. D. (2017). Modeling and learning incident prioritization. In Proceedings of the 2017 IEEE 9th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2017 (Vol. 1, pp. 398–403). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/IDAACS.2017.8095112*\n",
    "\n",
    "*Vaarandi, R. (2009). Real-time classification of IDS alerts with data mining techniques. In Proceedings - IEEE Military Communications Conference MILCOM. https://doi.org/10.1109/MILCOM.2009.5379762*\n",
    "\n",
    "*Wankhade, A., & Chandrasekaran, K. (2017). Distributed-Intrusion Detection System using combination of Ant Colony Optimization (ACO) and support vector machine (SVM). In Proceedings - 2016 International Conference on Micro-Electronics and Telecommunication Engineering, ICMETE 2016 (pp. 646–651). Institute of Electrical and Electronics Engineers Inc. https://doi.org/10.1109/ICMETE.2016.94*\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "**Team’s Biography **\n",
    "\n",
    "\n",
    "**Bikram Dangi:**\n",
    "Dev-Ops SME - \n",
    "Apart from my academic background where I spend most of my time programming in C++, Java, Html, Css, JavaScript, C#, R, I have focused my core concentration classes in wireless security, networking and security, database security, ethical hacking and other security related fields. I received hands on training on ethical hacking while working on my undergraduate coursework. At DSU I have taken classes like Intrusion Detection, malware analysis, computer forensics, reverse engineering, cryptography and others. Malware analysis and reverse engineering classes have closely prepared me on the analysis of malware artifacts. I also have a depth of field experience in software engineering working with many different projects.\n",
    "\n",
    "**Jeremy Gamet:**\n",
    "ML and Data SME -\n",
    "In addition to my Information Technology and Computer Science course work I have had five years of programming experience, done in a professional capacity. I have three years of information technology based professional work, and two years of HPC systems engineering experience. I have completed most of my programming projects in C/C++, C#, Matlab, R/Rstudio, Python (Jupyter Notebook), and JavaScript as well as Bash and Powershell. My project experience has been varied consisting of data science projects, systems engineering code, science code in parallel using CUDA, engineering tools in C#, ML algorithms via Matlab and Python, and system configuration tool scripting with various tools using Python, Ruby, powershell, and CFEngine. Overall however the largest bulk of my work has been done in backend analysis tool creation using C++ and orchestrating projects using DevOps tools for agile development. \n",
    "\n",
    "**Arica Kulm:**\n",
    "IT and Research SME - \n",
    "I am a first-year doctoral student in Cyber Defense.  I have a bachelor’s degree in Economics minoring in Computer Science and recently completed a master’s degree in Cyber Defense from Dakota State University.  I hold a Microsoft Certified Systems Engineer certification and have 15 years of experience in computer software/hardware installation, networking, training and support in the healthcare industry.  I am a highly organized, detail oriented, hard worker with excellent written and oral communication skills.\n",
    "\n",
    "**TJ Nelson:**\n",
    "Security and Attack Vector SME - \n",
    "I am a first-year doctoral student in Cyber Operations with over 10 years of professional information security experience. I currently work as a malware researcher and previously worked in consulting performing incident response and forensics. Throughout my career I have obtained various industry certifications:\n",
    "GIAC Reverse Engineering Malware\n",
    "GIAC Certified Forensic Analyst\n",
    "GIAC Penetration Tester\n",
    "GIAC Web Application Penetration Tester\n",
    "GIAC Certified Incident Handler\n",
    "GIAC Certified Intrusion Analyst\n",
    "I also have experience programming in various languages such as Python and C/C++.  My research interests include malware analysis, reverse engineering, forensics, incident response, software development , data analysis, machine learning and exploit development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBhhCSkv5v1z"
   },
   "source": [
    "## K-Means Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZ_pShVSdbmR"
   },
   "outputs": [],
   "source": [
    "# Dakota State University\n",
    "# CSC 791 - Collaborative Research\n",
    "# Last update: March 22, 2019\n",
    "# Todo:\n",
    "#\n",
    "#\n",
    "# (Expt) publish date: May 2019\n",
    "#\n",
    "# Title: Initial data exploration and testing of K-Means on CSE-CIC-IDS2018\n",
    "#\n",
    "# Current Learning Data Filename: \n",
    "# Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
    "# Subset of CSE-CIC-IDS2018\n",
    "\n",
    "############IMPORTS######################################\n",
    "import numpy as np                                      #\n",
    "import os                                               #\n",
    "import pandas as pd                                     #\n",
    "import sklearn as skl                                   #\n",
    "from sklearn.cluster import KMeans                      #\n",
    "import seaborn as sb                                    #\n",
    "import matplotlib.pyplot as plt                         #\n",
    "from mpl_toolkits.mplot3d import Axes3D                 #\n",
    "import io                                               #\n",
    "import pickle                                           #\n",
    "import requests                                         #\n",
    "from sklearn import preprocessing                       #\n",
    "from sklearn.decomposition import PCA                   #\n",
    "from matplotlib import colors as mcolors                #\n",
    "from sklearn.cluster import AgglomerativeClustering     #\n",
    "from sklearn.neighbors import LocalOutlierFactor        #\n",
    "############IMPORTS######################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "VVM9gA465t_J",
    "outputId": "ddd145cc-1e30-438c-e2ae-4cae25ac4f83"
   },
   "source": [
    "############ URL  Upload Routine ###############################################\n",
    "\n",
    "## Using CSE-CIC-IDS2018 ##\n",
    "\n",
    "\"\"\"\n",
    "# Use this if you want to grab the csv from a hosted page \n",
    "\n",
    "# Dataset is hosted at this url from a git repo as a .csv file format\n",
    "url=\"https://drive.google.com/open?id=1nW5rnd7Oge6NdgKEg-EJlMj2lzZBMmIC\"\n",
    "\n",
    "# Making an http request to download the file as http request content\n",
    "s=requests.get(url).content\n",
    "\n",
    "print(s)\n",
    "\n",
    "# Using the io library to convert the http request csv for pandas request\n",
    "csv=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "# Else use ...\n",
    "\"\"\"\n",
    "\n",
    "############ File Upload Routine ###############################################\n",
    "def upload_files():\n",
    "  from google.colab import files\n",
    "  uploaded = files.upload()\n",
    "  for k, v in uploaded.items():\n",
    "    open(k, 'wb').write(v)\n",
    "  return list(uploaded.keys())\n",
    "\n",
    "# List files in the current working directory\n",
    "! rm -Rf ./*;echo directory contents; pwd; echo ---;\n",
    "# Upload file from local computer to this notebook\n",
    "file = upload_files()\n",
    "! ls\n",
    "# Using pandas to read csv file\n",
    "csv_df=pd.read_csv('Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "\n",
    "csv_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "1czKKHY8cbK_",
    "outputId": "c9e4c0f7-e3dd-4609-8d4a-214cede351fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK Flag Cnt</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Bwd Blk Rate Avg</th>\n",
       "      <th>Bwd Byts/b Avg</th>\n",
       "      <th>Bwd Header Len</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>SYN Flag Cnt</th>\n",
       "      <th>Subflow Bwd Byts</th>\n",
       "      <th>Subflow Bwd Pkts</th>\n",
       "      <th>Subflow Fwd Byts</th>\n",
       "      <th>Subflow Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>URG Flag Cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>31525.0</td>\n",
       "      <td>8569.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>133669.0</td>\n",
       "      <td>18494.57143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>135611.0</td>\n",
       "      <td>21082.83333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACK Flag Cnt  Active Max  Active Mean  Active Min  Active Std  \\\n",
       "0           0.0         0.0          0.0         0.0         0.0   \n",
       "1           1.0         0.0          0.0         0.0         0.0   \n",
       "2           0.0         0.0          0.0         0.0         0.0   \n",
       "3           1.0         0.0          0.0         0.0         0.0   \n",
       "4           0.0         0.0          0.0         0.0         0.0   \n",
       "\n",
       "   Bwd Blk Rate Avg  Bwd Byts/b Avg  Bwd Header Len  Bwd IAT Max  \\\n",
       "0               0.0             0.0           152.0      31525.0   \n",
       "1               0.0             0.0            20.0          0.0   \n",
       "2               0.0             0.0           312.0     133669.0   \n",
       "3               0.0             0.0             0.0          0.0   \n",
       "4               0.0             0.0           272.0     135611.0   \n",
       "\n",
       "   Bwd IAT Mean  ...  SYN Flag Cnt  Subflow Bwd Byts  Subflow Bwd Pkts  \\\n",
       "0    8569.50000  ...           0.0            3773.0               7.0   \n",
       "1       0.00000  ...           1.0               0.0               1.0   \n",
       "2   18494.57143  ...           0.0           10527.0              15.0   \n",
       "3       0.00000  ...           0.0               0.0               0.0   \n",
       "4   21082.83333  ...           0.0            6141.0              13.0   \n",
       "\n",
       "   Subflow Fwd Byts  Subflow Fwd Pkts  Tot Bwd Pkts  Tot Fwd Pkts  \\\n",
       "0             553.0               9.0           7.0           9.0   \n",
       "1              38.0               2.0           1.0           2.0   \n",
       "2            1086.0              11.0          15.0          11.0   \n",
       "3               0.0               2.0           0.0           2.0   \n",
       "4            1285.0               9.0          13.0           9.0   \n",
       "\n",
       "   TotLen Bwd Pkts  TotLen Fwd Pkts  URG Flag Cnt  \n",
       "0           3773.0            553.0           0.0  \n",
       "1              0.0             38.0           0.0  \n",
       "2          10527.0           1086.0           0.0  \n",
       "3              0.0              0.0           0.0  \n",
       "4           6141.0           1285.0           0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ PART 1 - CONVERT/READ/CLEAN DATA ##################################\n",
    "csv_df = pd.read_pickle('processed_data_df.pkl')\n",
    "features = list(csv_df)\n",
    "atype = type(\"string\")\n",
    "for i in range(len(features)):\n",
    "  if type(csv_df[ features[i] ].values[1])==  atype:\n",
    "      csv_df = csv_df.drop([features[i]], axis=1)\n",
    "\n",
    "features = list(csv_df)\n",
    "csv_df = csv_df.dropna()\n",
    "csv_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "O1a4PQ7gzHSA",
    "outputId": "ce8615b2-dcb9-4c7a-d11d-602f179c86ac"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ PART 2 - INITIAL ANALYSIS #########################################\n",
    "\n",
    "for i in range(len(features)):\n",
    "  csv_df[features[i]] =  pd.to_numeric(csv_df[features[i]], errors='coerce')\n",
    "\n",
    "# Creating a new normalized dataframe\n",
    "X = csv_df[features].dropna()\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(np_scaled)\n",
    "\n",
    "# Principle Component Analasys Step\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(X)\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(np_scaled)\n",
    "\n",
    "# declaring n as number of possible centroids (aka cluster centers)\n",
    "n = range(1,20)\n",
    "\n",
    "# creating an empty KMeans class object called kmeans set to have n centroids\n",
    "kmeans = [KMeans(n_clusters=i).fit(X) for i in n]\n",
    "scores = [kmeans[i].score(X) for i in range(len(kmeans))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(n, scores)\n",
    "plt.xlim(0,20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "BMIdBzMJzJQ6",
    "outputId": "98e7c597-3d70-4cc0-a976-2a121a8a9029"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ PART 3 - VISUALIZATION AND DETECTION ##############################\n",
    "kmeans = KMeans(n_clusters=4).fit(X)\n",
    "# selecting number of clusters to be 5 for plotting\n",
    "X[3] = kmeans.predict(X)\n",
    "\n",
    "# calling matplotlib scatter() method to plot the clusters w/labels\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[0],X[1],X[2],c=X[3], cmap='rainbow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "5oHaPHVLdDge",
    "outputId": "f1bc3af5-39f2-4559-9e32-6802b54e6c06"
   },
   "outputs": [],
   "source": [
    "\n",
    "######### Trying LOF outlier detection  ########################################\n",
    "# fit the model for outlier detection (default)\n",
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "y_pred = clf.fit_predict(X)\n",
    "ground_truth = np.ones(len(X), dtype=int)\n",
    "n_errors = (y_pred != ground_truth).sum()\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "\n",
    "plt.title(\"Local Outlier Factor (LOF)\")\n",
    "plt.scatter(X[0], X[1], \n",
    "            color='k', s=3., label='Data points')\n",
    "\n",
    "# plot circles with radius proportional to the outlier scores\n",
    "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
    "plt.scatter(X[1], X[2],\n",
    "            s=1000 * radius, edgecolors='r',\n",
    "            facecolors='none', label='Outlier scores')\n",
    "plt.axis('tight')\n",
    "plt.xlim((-10, 10))\n",
    "plt.ylim((-10, 10))\n",
    "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
    "legend = plt.legend(loc='upper left')\n",
    "legend.legendHandles[0]._sizes = [10]\n",
    "legend.legendHandles[1]._sizes = [20]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Initial K-Means Data Exploration and Visuals.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
